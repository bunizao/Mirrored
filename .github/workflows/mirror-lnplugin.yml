name: Mirror LNPlugin Artifacts

on:
  schedule:
    - cron: '10,35,59 * * * *'
  workflow_dispatch:

jobs:
  mirror:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    env:
      # 主源 + 备用源（可继续加更多 FALLBACK_URL_*）
      SOURCE_URL: https://hub.kelee.one/list.json
      FALLBACK_URL_1: https://pluginhub.kelee.one/list.json

      # 桥接只读源（用于绕过 JS Challenge；不要的话设为空字符串）
      # 同时尝试 http:// 与 https:// 两种上游拼法
      BRIDGE_PREFIX: 'https://r.jina.ai/http://'
      BRIDGE_PREFIX_ALT: 'https://r.jina.ai/https://'

      # （可选）你的自建反代/Worker 网关（留空则不用）
      # PROXY_BASE: 'https://your-worker.example.workers.dev/fetch?url='

      # 请求头与调试
      USER_AGENT: 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
      ACCEPT_HEADER: 'application/json, text/plain, */*'
      REFERER: 'https://pluginhub.kelee.one/'
      DEBUG_CURL: '1'  # 稳定后可调成 0

    steps:
      - name: Checkout main branch
        uses: actions/checkout@v3
        with:
          ref: main

      - name: Configure git author
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

      - name: Download plugin catalog (multi-fallback + smart JSON extract + cache)
        run: |
          set -euo pipefail

          mkdir -p Cache

          urls=()
          urls+=("${SOURCE_URL}")
          [ -n "${FALLBACK_URL_1:-}" ] && urls+=("${FALLBACK_URL_1}")

          # 拼接桥接只读源（最后尝试）
          if [ -n "${BRIDGE_PREFIX:-}" ] || [ -n "${BRIDGE_PREFIX_ALT:-}" ]; then
            for u in "${SOURCE_URL}" "${FALLBACK_URL_1:-}"; do
              [ -z "${u:-}" ] && continue
              host_path="${u#https://}"  # 兼容 https://host/path
              [ -n "${BRIDGE_PREFIX:-}" ] && urls+=("${BRIDGE_PREFIX}${host_path}")
              [ -n "${BRIDGE_PREFIX_ALT:-}" ] && urls+=("${BRIDGE_PREFIX_ALT}${host_path}")
            done
          fi

          # 自建反代（可选）
          if [ -n "${PROXY_BASE:-}" ]; then
            for u in "${SOURCE_URL}" "${FALLBACK_URL_1:-}"; do
              [ -z "${u:-}" ] && continue
              urls+=("${PROXY_BASE}${u}")
            done
          fi

          base_flags=(--fail --show-error --location --compressed --http1.1 \
                      --retry 5 --retry-all-errors --connect-timeout 20 --max-time 120 \
                      -A "$USER_AGENT" -H "Accept: $ACCEPT_HEADER" -e "$REFERER")

          is_bridge_url() {
            case "$1" in
              https://r.jina.ai/*) return 0 ;;
              *) return 1 ;;
            esac
          }

          do_preflight() {
            local u="$1"
            echo "::group::Preflight ${u}"
            if is_bridge_url "$u"; then
              # r.jina.ai 不支持 HEAD，用 GET 取 1 字节做轻量预检
              if [ "${DEBUG_CURL}" = "1" ]; then
                curl -sS -D - -o /dev/null -r 0-0 --http1.1 \
                  -A "$USER_AGENT" -H "Accept: $ACCEPT_HEADER" "$u" | tee -a curl_head.log || true
              else
                curl -sS -D - -o /dev/null -r 0-0 --http1.1 \
                  -A "$USER_AGENT" -H "Accept: $ACCEPT_HEADER" "$u" >> curl_head.log 2>/dev/null || true
              fi
            else
              if [ "${DEBUG_CURL}" = "1" ]; then
                curl -sS -I --http1.1 \
                  -A "$USER_AGENT" -H "Accept: $ACCEPT_HEADER" -e "$REFERER" "$u" | tee -a curl_head.log || true
              else
                curl -sS -I --http1.1 \
                  -A "$USER_AGENT" -H "Accept: $ACCEPT_HEADER" -e "$REFERER" "$u" >> curl_head.log 2>/dev/null || true
              fi
            fi
            echo "::endgroup::"
          }

          try_clean_json() {
            # 尝试把 text/plain 中的 JSON 从混杂文本中提取出来
            python3 - "$1" "$2" <<'PY'
import sys, json, re
src_path, out_path = sys.argv[1], sys.argv[2]
src = open(src_path,'rb').read().decode('utf-8','ignore')

def write_clean(obj):
    with open(out_path,'w',encoding='utf-8') as f:
        json.dump(obj, f, ensure_ascii=False, separators=(',',':'))

# 1) 直接 JSON
try:
    obj = json.loads(src)
    write_clean(obj)
    sys.exit(0)
except Exception:
    pass

# 2) ```json 代码块
m = re.search(r"```(?:json)?\s*({.*?})\s*```", src, re.S|re.I)
if m:
    try:
        obj = json.loads(m.group(1))
        write_clean(obj); sys.exit(0)
    except Exception:
        pass

# 3) 提取文本中“最大平衡 {} 块”
def largest_braced(text):
    stack = []
    best_seg = None
    start = None
    for i, ch in enumerate(text):
        if ch == '{':
            if not stack: start = i
            stack.append('{')
        elif ch == '}' and stack:
            stack.pop()
            if not stack and start is not None:
                seg = text[start:i+1]
                if best_seg is None or len(seg) > len(best_seg):
                    best_seg = seg
                start = None
    return best_seg

cand = largest_braced(src)
if cand:
    # 去掉可能的 BOM/前后空白
    cand = cand.strip()
    try:
        obj = json.loads(cand)
        write_clean(obj); sys.exit(0)
    except Exception:
        pass

sys.exit(2)
PY
          }

          fetch_ok=false
          FALLBACK_MODE=false
          rm -f plugin_data.json plugin_data.raw curl_head.log curl_debug.log || true

          for u in "${urls[@]}"; do
            do_preflight "$u"

            echo "::group::GET ${u}"
            if [ "${DEBUG_CURL}" = "1" ]; then
              curl "${base_flags[@]}" -v "$u" -D headers.tmp -o plugin_data.raw 2>>curl_debug.log || true
            else
              curl "${base_flags[@]}" "$u" -D headers.tmp -o plugin_data.raw || true
            fi
            echo "::endgroup::"

            if [ -s plugin_data.raw ]; then
              # 优先直接 jq 校验
              if command -v jq >/dev/null 2>&1 && jq . >/dev/null 2>&1 < plugin_data.raw; then
                mv plugin_data.raw plugin_data.json
                echo "✓ Catalog downloaded (valid JSON) from ${u}"
                fetch_ok=true
                break
              else
                echo "::warning ::Downloaded catalog not valid JSON from ${u}; trying to extract"
                if try_clean_json plugin_data.raw plugin_data.json; then
                  echo "✓ Extracted JSON from text/plain (${u})"
                  fetch_ok=true
                  break
                else
                  echo "::warning ::Failed to extract JSON from ${u}"
                  rm -f plugin_data.json || true
                fi
              fi
            else
              echo "::warning ::Empty response from ${u}"
            fi
            rm -f plugin_data.raw headers.tmp || true
          done

          if [ "${fetch_ok}" != "true" ]; then
            # 使用仓库内上一版缓存，进入回退模式（避免全流程中断）
            if [ -f Cache/plugin_data.json ] && [ -s Cache/plugin_data.json ]; then
              echo "::warning ::Using cached Cache/plugin_data.json (fallback mode)"
              cp Cache/plugin_data.json plugin_data.json
              FALLBACK_MODE=true
            else
              echo "::group::curl debug logs"
              [ -f curl_head.log ] && cat curl_head.log || true
              [ -f curl_debug.log ] && tail -n +1 curl_debug.log || true
              echo "::endgroup::"
              echo "::error ::Failed to download plugin catalog from all sources and no cache available"
              exit 1
            fi
          fi

          # 成功获取则更新缓存
          if [ "${fetch_ok}" = "true" ]; then
            cp plugin_data.json Cache/plugin_data.json
            echo "REFRESHED_JSON=true" >> "$GITHUB_ENV"
          else
            echo "REFRESHED_JSON=false" >> "$GITHUB_ENV"
          fi

          echo "FALLBACK_MODE=${FALLBACK_MODE}" >> "$GITHUB_ENV"

      - name: Extract LNPlugin URLs
        run: |
          set -euo pipefail
          python3 scripts/extract_lnplugin_urls.py \
            --input plugin_data.json \
            --output lnplugin_urls.txt

      - name: Mirror LNPlugin packages (safe-delete aware)
        run: |
          set -euo pipefail
          mkdir -p Chores/lnplugin

          mapfile -t urls < lnplugin_urls.txt
          if [ "${#urls[@]}" -eq 0 ]; then
            echo "::error ::No LNPlugin URLs to mirror"
            exit 1
          fi

          declare -A seen
          updated=false

          # 回退模式下不做“缺失即删除”的清理，防止因旧清单误删
          SAFE_DELETE=true
          if [ "${FALLBACK_MODE:-false}" = "true" ]; then
            echo "::warning ::Fallback mode ON - stale deletion disabled"
            SAFE_DELETE=false
          fi

          for filepath in Chores/lnplugin/*.lpx; do
            if [ -e "$filepath" ]; then
              seen["$(basename "$filepath")"]=false
            fi
          done

          base_flags=(--fail --show-error --location --compressed --http1.1 \
                      --retry 5 --retry-all-errors --connect-timeout 30 --max-time 120 \
                      -A "$USER_AGENT" -H "Accept: $ACCEPT_HEADER")

          for url in "${urls[@]}"; do
            url="${url//$'\r'/}"
            url="${url//$'\n'/}"
            [ -z "$url" ] && continue

            sanitized="${url%%[\?#]*}"
            filename="$(basename "$sanitized")"
            filename="${filename//$'\r'/}"
            filename="${filename//$'\n'/}"

            if [[ -z "$filename" ]]; then
              echo "::warning ::Skipping malformed URL: $url"
              continue
            fi
            if [[ ! "$filename" =~ \.lpx$ ]]; then
              filename="${filename}.lpx"
            fi

            temp_file="Chores/lnplugin/$filename.tmp"
            final_file="Chores/lnplugin/$filename"

            echo "↓  $url"
            if [ "${DEBUG_CURL}" = "1" ]; then
              echo "::group::curl $filename"
              curl "${base_flags[@]}" -v "$url" -o "$temp_file" 2> "curl_${filename}.log" || true
              echo "::endgroup::"
            else
              curl "${base_flags[@]}" "$url" -o "$temp_file" || true
            fi

            if [ -s "$temp_file" ]; then
              if ! cmp -s "$temp_file" "$final_file" 2>/dev/null; then
                mv "$temp_file" "$final_file"
                updated=true
                echo "✓ Mirrored $filename"
              else
                rm -f "$temp_file"
                echo "= $filename unchanged"
              fi
            else
              echo "::warning ::Downloaded file empty: $filename"
              rm -f "$temp_file"
            fi

            seen["$filename"]=true
          done

          if [ "${SAFE_DELETE}" = "true" ]; then
            for filename in "${!seen[@]}"; do
              if [ "${seen[$filename]}" = false ]; then
                echo "Removing stale artifact: $filename"
                rm -f "Chores/lnplugin/$filename"
                updated=true
              fi
            done
          else
            echo "::notice ::Skip stale deletion due to fallback mode"
          fi

          if [ "$updated" = true ]; then
            echo "MIRROR_UPDATED=true" >> "$GITHUB_ENV"
          else
            echo "MIRROR_UPDATED=false" >> "$GITHUB_ENV"
          fi

      - name: Commit and push changes
        if: env.MIRROR_UPDATED == 'true' || env.REFRESHED_JSON == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e
          git add Chores/lnplugin Cache/plugin_data.json

          if git diff --cached --quiet; then
            echo "No changes to commit"
            exit 0
          fi

          git fetch origin
          git pull --rebase origin main
          git add Chores/lnplugin Cache/plugin_data.json

          timestamp=$(TZ='Asia/Shanghai' date '+%Y-%m-%d %H:%M:%S')
          git commit -m "🪞 Mirror LNPlugin artifacts - $timestamp (UTC+8)"
          git push origin main

      - name: No updates detected
        if: env.MIRROR_UPDATED != 'true' && env.REFRESHED_JSON != 'true'
        run: echo "LNPlugin artifacts already up to date (or fallback used with no changes)"
