name: Mirror LNPlugin Artifacts

on:
  schedule:
    - cron: '10,35,59 * * * *'
  workflow_dispatch:

jobs:
  mirror:
    runs-on: ubuntu-latest
    permissions:
      contents: write
    env:

      PROXY_BASE: https://wowproxy.lyetutu.workers.dev/?url=

      LIST_URL_PRIMARY: https://hub.kelee.one/list.json
      LIST_URL_BACKUP: https://pluginhub.kelee.one/list.json

      # ËØ∑Ê±ÇÂ§¥‰∏éË∞ÉËØï
      USER_AGENT: 'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
      ACCEPT_HEADER: 'application/json, text/plain, */*'
      REFERER: 'https://pluginhub.kelee.one/'
      DEBUG_CURL: '0'  # ÈúÄË¶ÅÊéíÊü•Êó∂Êîπ‰∏∫ 1

    steps:
      - name: Checkout main branch
        uses: actions/checkout@v3
        with:
          ref: main

      - name: Configure git author
        run: |
          git config --global user.name "github-actions[bot]"
          git config --global user.email "github-actions[bot]@users.noreply.github.com"

      - name: Download plugin catalog (proxy-only + smart JSON extract + cache + masking)
        run: |
          set -euo pipefail

          mkdir -p Cache

          : "${PROXY_BASE:?PROXY_BASE secret required}"
          : "${LIST_URL_PRIMARY:?LIST_URL_PRIMARY secret required}"
          # LIST_URL_BACKUP ÂèØ‰∏∫Á©∫

          # ËßÑËåÉÂåñ PROXY_BASEÔºåÁ°Æ‰øù‰ª• ?url= ÁªìÂ∞æ
          if [[ "$PROXY_BASE" != *"?url="* ]]; then
            PROXY_BASE="${PROXY_BASE%/}?url="
          fi

          # URL ÁºñÁ†ÅÔºàÁî® PythonÔºåÈÄöÁî®Á®≥ÂÆöÔºâ
          ENC_PRIMARY="$(python3 - <<'PY'
import os, urllib.parse
print(urllib.parse.quote(os.environ['LIST_URL_PRIMARY'], safe=''))
PY
)"
          ENC_BACKUP=""
          if [ -n "${LIST_URL_BACKUP:-}" ]; then
            ENC_BACKUP="$(python3 - <<'PY'
import os, urllib.parse
print(urllib.parse.quote(os.environ['LIST_URL_BACKUP'], safe=''))
PY
)"
          fi

          # Êó•ÂøóËÑ±ÊïèÔºàÂéüÂßã/ÁºñÁ†Å/ÊúÄÁªà‰ª£ÁêÜ URL ÂÖ®ÈÉ®ÈÅÆÁΩ©Ôºâ
          echo "::add-mask::$LIST_URL_PRIMARY"
          [ -n "${LIST_URL_BACKUP:-}" ] && echo "::add-mask::$LIST_URL_BACKUP"
          echo "::add-mask::$ENC_PRIMARY"
          [ -n "$ENC_BACKUP" ] && echo "::add-mask::$ENC_BACKUP"
          echo "::add-mask::${PROXY_BASE}${ENC_PRIMARY}"
          [ -n "$ENC_BACKUP" ] && echo "::add-mask::${PROXY_BASE}${ENC_BACKUP}"

          # Âè™Ëµ∞‰ª£ÁêÜÊãâÂèñÔºàÁÆÄÂåñ & Á®≥ÂÆöÔºâ
          urls=("${PROXY_BASE}${ENC_PRIMARY}")
          [ -n "$ENC_BACKUP" ] && urls+=("${PROXY_BASE}${ENC_BACKUP}")

          base_flags=(--fail --show-error --location --compressed --http1.1 \
                      --retry 5 --retry-all-errors --connect-timeout 20 --max-time 120 \
                      -A "$USER_AGENT" -H "Accept: $ACCEPT_HEADER" -e "$REFERER")

          try_clean_json() {
            python3 - "$1" "$2" <<'PY'
import sys, json, re
src_path, out_path = sys.argv[1], sys.argv[2]
src = open(src_path,'rb').read().decode('utf-8','ignore')

def write_clean(obj):
    with open(out_path,'w',encoding='utf-8') as f:
        json.dump(obj, f, ensure_ascii=False, separators=(',',':'))

# 1) Áõ¥Êé• JSON
try:
    write_clean(json.loads(src)); sys.exit(0)
except Exception:
    pass

# 2) ```json ‰ª£Á†ÅÂùó
m = re.search(r"```(?:json)?\s*({.*?})\s*```", src, re.S|re.I)
if m:
    try:
        write_clean(json.loads(m.group(1))); sys.exit(0)
    except Exception:
        pass

# 3) ÊèêÂèñÊúÄÂ§ßÂπ≥Ë°° {} Âùó
def largest_braced(text):
    stack = []; best = None; start = None
    for i,ch in enumerate(text):
        if ch=='{':
            if not stack: start = i
            stack.append('{')
        elif ch=='}' and stack:
            stack.pop()
            if not stack and start is not None:
                seg = text[start:i+1]
                if best is None or len(seg) > len(best): best = seg
                start = None
    return best

cand = largest_braced(src)
if cand:
    cand = cand.strip()
    try:
        write_clean(json.loads(cand)); sys.exit(0)
    except Exception:
        pass

sys.exit(2)
PY
          }

          fetch_ok=false
          FALLBACK_MODE=false
          rm -f plugin_data.json plugin_data.raw curl_debug.log headers.tmp || true

          for u in "${urls[@]}"; do
            if [ "${DEBUG_CURL}" = "1" ]; then
              curl "${base_flags[@]}" "$u" -D headers.tmp -o plugin_data.raw -v 2>>curl_debug.log || true
            else
              curl "${base_flags[@]}" "$u" -D headers.tmp -o plugin_data.raw || true
            fi

            if [ -s plugin_data.raw ]; then
              if command -v jq >/dev/null 2>&1 && jq . >/dev/null 2>&1 < plugin_data.raw; then
                mv plugin_data.raw plugin_data.json
                echo "‚úì Catalog downloaded (valid JSON) via proxy"
                fetch_ok=true; break
              else
                echo "::notice ::Downloaded body not strict-JSON; trying smart extractor"
                if try_clean_json plugin_data.raw plugin_data.json; then
                  echo "‚úì Extracted JSON from text via proxy"
                  fetch_ok=true; break
                else
                  echo "::warning ::Smart extract failed on this source"
                  rm -f plugin_data.json || true
                fi
              fi
            else
              echo "::warning ::Empty response from proxy source"
            fi
            rm -f plugin_data.raw headers.tmp || true
          done

          if [ "${fetch_ok}" != "true" ]; then
            if [ -f Cache/plugin_data.json ] && [ -s Cache/plugin_data.json ]; then
              echo "::warning ::Using cached Cache/plugin_data.json (fallback mode)"
              cp Cache/plugin_data.json plugin_data.json
              FALLBACK_MODE=true
            else
              [ -f curl_debug.log ] && { echo "::group::curl debug"; tail -n +1 curl_debug.log || true; echo "::endgroup::"; }
              echo "::error ::Failed to download plugin catalog via proxy and no cache available"
              exit 1
            fi
          fi

          if [ "${fetch_ok}" = "true" ]; then
            cp plugin_data.json Cache/plugin_data.json
            echo "REFRESHED_JSON=true" >> "$GITHUB_ENV"
          else
            echo "REFRESHED_JSON=false" >> "$GITHUB_ENV"
          fi
          echo "FALLBACK_MODE=${FALLBACK_MODE}" >> "$GITHUB_ENV"

      - name: Extract LNPlugin URLs
        run: |
          set -euo pipefail
          python3 scripts/extract_lnplugin_urls.py \
            --input plugin_data.json \
            --output lnplugin_urls.txt

      - name: Mirror LNPlugin packages (safe-delete aware)
        run: |
          set -euo pipefail
          mkdir -p Chores/lnplugin

          mapfile -t urls < lnplugin_urls.txt
          if [ "${#urls[@]}" -eq 0 ]; then
            echo "::error ::No LNPlugin URLs to mirror"
            exit 1
          fi

          declare -A seen
          updated=false

          # ÂõûÈÄÄÊ®°Âºè‰∏ã‰∏çÂà†ÊóßÂ∑•‰ª∂ÔºåÈÅøÂÖçËØØÂà†
          SAFE_DELETE=true
          if [ "${FALLBACK_MODE:-false}" = "true" ]; then
            echo "::warning ::Fallback mode ON - stale deletion disabled"
            SAFE_DELETE=false
          fi

          for filepath in Chores/lnplugin/*.lpx; do
            if [ -e "$filepath" ]; then
              seen["$(basename "$filepath")"]=false
            fi
          done

          base_flags=(--fail --show-error --location --compressed --http1.1 \
                      --retry 5 --retry-all-errors --connect-timeout 30 --max-time 120 \
                      -A "$USER_AGENT" -H "Accept: $ACCEPT_HEADER")

          for url in "${urls[@]}"; do
            url="${url//$'\r'/}"
            url="${url//$'\n'/}"
            [ -z "$url" ] && continue

            sanitized="${url%%[\?#]*}"
            filename="$(basename "$sanitized")"
            filename="${filename//$'\r'/}"
            filename="${filename//$'\n'/}"

            if [[ -z "$filename" ]]; then
              echo "::warning ::Skipping malformed URL: $url"
              continue
            fi
            [[ "$filename" != *.lpx ]] && filename="${filename}.lpx"

            temp_file="Chores/lnplugin/$filename.tmp"
            final_file="Chores/lnplugin/$filename"

            echo "‚Üì  $url"
            if [ "${DEBUG_CURL}" = "1" ]; then
              echo "::group::curl $filename"
              curl "${base_flags[@]}" -v "$url" -o "$temp_file" 2> "curl_${filename}.log" || true
              echo "::endgroup::"
            else
              curl "${base_flags[@]}" "$url" -o "$temp_file" || true
            fi

            if [ -s "$temp_file" ]; then
              if ! cmp -s "$temp_file" "$final_file" 2>/dev/null; then
                mv "$temp_file" "$final_file"
                updated=true
                echo "‚úì Mirrored $filename"
              else
                rm -f "$temp_file"
                echo "= $filename unchanged"
              fi
            else
              echo "::warning ::Downloaded file empty: $filename"
              rm -f "$temp_file"
            fi

            seen["$filename"]=true
          done

          if [ "${SAFE_DELETE}" = "true" ]; then
            for filename in "${!seen[@]}"; do
              if [ "${seen[$filename]}" = false ]; then
                echo "Removing stale artifact: $filename"
                rm -f "Chores/lnplugin/$filename"
                updated=true
              fi
            done
          else
            echo "::notice ::Skip stale deletion due to fallback mode"
          fi

          if [ "$updated" = true ]; then
            echo "MIRROR_UPDATED=true" >> "$GITHUB_ENV"
          else
            echo "MIRROR_UPDATED=false" >> "$GITHUB_ENV"
          fi

      - name: Commit and push changes
        if: env.MIRROR_UPDATED == 'true' || env.REFRESHED_JSON == 'true'
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
        run: |
          set -e
          git add Chores/lnplugin Cache/plugin_data.json

          if git diff --cached --quiet; then
            echo "No changes to commit"
            exit 0
          fi

          git fetch origin
          git pull --rebase origin main
          git add Chores/lnplugin Cache/plugin_data.json

          timestamp=$(TZ='Asia/Shanghai' date '+%Y-%m-%d %H:%M:%S')
          git commit -m "ü™û Mirror LNPlugin artifacts - $timestamp (UTC+8)"
          git push origin main

      - name: No updates detected
        if: env.MIRROR_UPDATED != 'true' && env.REFRESHED_JSON != 'true'
        run: echo "LNPlugin artifacts already up to date (or fallback used with no changes)"
